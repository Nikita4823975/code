{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20c78a86-e6e9-4dc7-a4fe-ca3d28f48c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4fb4cef-f777-4514-a128-273501b1609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "443489eb-4379-4493-9bd6-70a374da9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc1d0200-b860-446e-8b71-83152e33a551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ce98a91-7583-4a2c-b4cd-d079a2dacef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0984, -0.0566,  0.0889,  0.0924,  0.1052,  0.0263,  0.0028, -0.0471,\n",
      "         -0.0064, -0.0136]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Predicted class: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9ac624b-03bf-4363-871b-7cf98c1f7b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5ff5663-ec92-4284-95db-b8eb48e94425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec1c6255-f0c2-4079-a9a5-3833128ff0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be1cf621-d9c9-4d9a-85e3-56a6e9cce149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.1080, -0.0959,  0.1978,  0.1573, -0.8635, -0.1770, -0.9403, -0.0171,\n",
      "          0.4261, -0.1094, -0.5727,  0.0158, -0.0881,  0.5089,  0.0282,  0.2143,\n",
      "          0.1619,  0.2825, -0.0664,  0.5937],\n",
      "        [-0.0991, -0.3283,  0.0409,  0.2429, -0.4709, -0.2089, -0.5085, -0.1403,\n",
      "          0.8241, -0.0910, -0.2388,  0.1878,  0.0804,  0.5614, -0.2330,  0.1529,\n",
      "          0.0434, -0.1591,  0.0607,  0.2432],\n",
      "        [-0.2123, -0.4033, -0.0020,  0.5870, -0.5255, -0.2386, -0.6133,  0.1225,\n",
      "          0.3920,  0.0893, -0.5020,  0.0957, -0.0507,  0.6729, -0.1277,  0.2829,\n",
      "          0.1088, -0.0764, -0.4628,  0.3914]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.1080, 0.0000, 0.1978, 0.1573, 0.0000, 0.0000, 0.0000, 0.0000, 0.4261,\n",
      "         0.0000, 0.0000, 0.0158, 0.0000, 0.5089, 0.0282, 0.2143, 0.1619, 0.2825,\n",
      "         0.0000, 0.5937],\n",
      "        [0.0000, 0.0000, 0.0409, 0.2429, 0.0000, 0.0000, 0.0000, 0.0000, 0.8241,\n",
      "         0.0000, 0.0000, 0.1878, 0.0804, 0.5614, 0.0000, 0.1529, 0.0434, 0.0000,\n",
      "         0.0607, 0.2432],\n",
      "        [0.0000, 0.0000, 0.0000, 0.5870, 0.0000, 0.0000, 0.0000, 0.1225, 0.3920,\n",
      "         0.0893, 0.0000, 0.0957, 0.0000, 0.6729, 0.0000, 0.2829, 0.1088, 0.0000,\n",
      "         0.0000, 0.3914]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23638f8e-436c-4485-93f5-5c44c6a0aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15517640-c775-4ced-851c-c324974f3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25d51e0b-4aa2-4e1e-9ecb-3c6e77fd45cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0133, -0.0134,  0.0258,  ...,  0.0287, -0.0044,  0.0123],\n",
      "        [-0.0076, -0.0056,  0.0096,  ..., -0.0048, -0.0123, -0.0119]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0221, -0.0158], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0254,  0.0112,  0.0326,  ...,  0.0249, -0.0079, -0.0243],\n",
      "        [ 0.0097, -0.0182,  0.0262,  ..., -0.0344,  0.0014,  0.0388]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0355,  0.0441], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0394,  0.0086, -0.0125,  ..., -0.0395,  0.0421,  0.0148],\n",
      "        [ 0.0113, -0.0059,  0.0344,  ..., -0.0393,  0.0439, -0.0090]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0036, 0.0331], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35fa303-959c-4178-9c16-27a22e09ff1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
